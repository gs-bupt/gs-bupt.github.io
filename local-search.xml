<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>transformer</title>
    <link href="/2023/08/20/transformer/"/>
    <url>/2023/08/20/transformer/</url>
    
    <content type="html"><![CDATA[<p>翻译自<a href="http://jalammar.github.io/illustrated-transformer/">http://jalammar.github.io/illustrated-transformer/</a></p><h2 id="整体角度">整体角度</h2><p>让我们将模型看作一个黑盒，在机器翻译应用中，它接收一种语言的句子，并输出另一种语言的翻译。</p><img src="/2023/08/20/transformer/the_transformer_3.png" class="" title="img"><p>打开这个擎天柱的内部，我们可以看到编码组件、解码组件以及它们之间的连接。</p><img src="/2023/08/20/transformer/The_transformer_encoders_decoders.png" class="" title="img"><p>编码组件是由一堆编码器堆叠而成(在transformer论文中，使用了6层)，解码组件也是同样数量的解码器的堆叠。</p><img src="/2023/08/20/transformer/The_transformer_encoder_decoder_stack.png" class="" title="img"><p>所有编码器在结构上都是相同的，但是它们不共享权重。每个编码器可以被分解为两个子层。</p><img src="/2023/08/20/transformer/Transformer_encoder.png" class="" title="img"><p>编码器的输入首先进入一个自注意力层——一个帮助编码器在编码特定单词时查看输入句子中其他单词的层。我们稍后会在本文中更加详细的介绍自注意力。</p><p>自注意力层的输出会被送到前馈神经网络层。完全相同的前馈神经网络独立的应用于每个位置。</p><p>解码器同样具有这两层，但是在这两层中间又添加了一个注意力层，用来帮助解码器集中关注句子的相关部分（类似于seq2seq模型中的注意力机制）。</p><img src="/2023/08/20/transformer/Transformer_decoder.png" class="" title="img"><h2 id="引入张量">引入张量</h2><p>现在我们已经了解了模型的主要组成部分，接下来让我们开始看看各种向量/张量是如何在这些组件之间流动以及如何将输入经过训练的模型转为输出的。</p><p>一般情况下，在自然语处理应用中，我们首先使用嵌入算法将每个输入的单词转为一个向量。每个单词被转换为一个大小为512的向量。我们将用这些简单的框表示这些向量。</p><img src="/2023/08/20/transformer/embeddings.png" class="" title="img"><p>嵌入层只在最底层的编码器中出现。所有编码器共有的抽象是，它们接收一个向量列表，每个向量的大小为512。在最底层的编码器中，它接收输入序列词嵌入转换后的向量列表，但是在其他编码器中，接收下一层的输出作为输入。这个列表的大小是一个超参数，一般是训练数据集中最长句子的长度。</p><p>对输入序列中的词进行嵌入转换后，它们每次都会经过编码器的两个层。</p><img src="/2023/08/20/transformer/encoder_with_tensors.png" class="" title="img"><p>这里我们开始看到Transformer的一个关键特性，即每个位置上的单词都会在编码器中通过自己的路径流动。在自注意力层中，这些路径之间存在依赖关系。然而，在前馈神经网络层没有这些路径依赖关系，因此在通过前馈层时，各个路径可以并行执行。</p><h2 id="现在开始编码">现在开始编码</h2><p>正如我们之前提到的，编码器接收一个向量列表作为输入。它通过将这些向量传递到自注意力层，然后传递到前馈神经网络来处理这个列表，然后将输出向上发送到下一个编码器。</p><img src="/2023/08/20/transformer/encoder_with_tensors_2.png" class="" title="img"><p>每个位置上的单词都会通过自注意力层的处理。然后，它们都会通过一个前馈神经网络 —— 每一个向量都会独立地通过完全相同地网络进行处理。</p><h2 id="高层次地自注意力机制">高层次地自注意力机制</h2><p>不要被我随意使用“self-attention”这个词而感到困惑，这好像是每个人都应该熟悉的概念。但是就我个人而言，在阅读《Attention is All You Need》论文之前，我从未接触过这个概念。让我们梳理一下它是怎么工作的。</p><p>假设以下句子是我们想要翻译的输入句子：</p><p>”<code>The animal didn't cross the street because it was too tired</code>”</p><p>在这个句子中，&quot;it&quot;指的是什么?它是指这条街道还是这只动物?对于人类来说，这是一个简单的问题，但是如果从算法的角度来考虑却没那么简单。</p><p>当模型处理单词 “it” 时，自注意力使它能够将 “it” 与 “animal” 关联起来。</p><p>当模型处理每个单词（输入序列中的每个位置）时，自注意力允许它查看输入序列中的其他位置，以获取有助于更好地对该单词进行编码的线索。</p><p>如果你熟悉RNN,可以把它维护一个隐状态的方式看作是RNN将它对前面单词/向量的表示与当前处理的单词相结合的方式。自注意力机制可以看作是Transformer模型关联前后文信息,将上下文语义融入当前词表示的关键机制。</p><img src="/2023/08/20/transformer/transformer_self-attention_visualization.png" class="" title="img"><p>当我们在第5个编码器(栈顶编码器)中编码“it”这个词时,注意力机制的一部分聚焦在了“The Animal”上,并将其表示的一部分融合到了“it”的编码中。</p><h2 id="自注意力机制的细节">自注意力机制的细节</h2><p>让我们先看看如何使用向量计算自注意力，然后查看它的实际实现——使用矩阵。</p><p>计算自注意力的<strong>第一步</strong>是从编码器的每个输入向量(在本例中，每个词的嵌入向量)创建三个向量。所以对于每个词，我们创建一个查询向量、键向量和值向量。这些向量是通过将嵌入向量与训练过程中学习到的三个矩阵相乘而创建的。</p><p>注意，这些新向量的维度比嵌入向量的维度小。它们的维度是64，而嵌入向量和编码器输入/输出向量的维度是512。它们不一定要更小，这是一种架构选择，以使多头注意力的计算量是常数级别的。</p><img src="/2023/08/20/transformer/transformer_self_attention_vectors.png" class="" title="img"><p>什么是查询、键、值向量？</p><p>它们是注意力计算和思考中有用的抽象概念。在下面阅读注意力计算方式后，你会对每个向量扮演的角色有足够的了解。</p><p>计算自注意力的<strong>第二步</strong>是计算分数，假设我们正在计算第一个词“Thinking”的自注意力。我们需要对输入句子的每个词根据该词给出一个分数。这个分数决定了当我们编码某个位置的词时，应该关注输入句子的其它部分的多少。</p><p>分数的计算是通过查询向量与我们正在评分的词的键向量的点积来实现的。所以如果我们正在处理位置#1的词的自注意力，第一个分数将是q1与k1的点积。第二个分数将是q1和k2的点积。</p><img src="/2023/08/20/transformer/transformer_self_attention_score.png" class="" title="img"><p>计算自注意力的<strong>第三步</strong>和<strong>第四步</strong>是将分数除以8（论文中使用的键向量的维度64的平方根。这可以让梯度更加稳定。这里也可以使用其他值,但默认是8)），然后将结果传递给softmax操作。Softmax将分数归一化，是他们都是正数并且加起来等于1.</p><img src="/2023/08/20/transformer/self-attention_softmax.png" class="" title="img"><p>这个softmax分数决定了每个词在该位置的表达程度。显然，该位置上的词将具有最高的softmax分数，但有时候关注与当前词相关的另一个词也很有用。</p><p>具体来说:</p><p>softmax分数表示了每个词对当前词位置的注意力权重。当前词位置上的词通常有最高的权重，但是其他相关词的权重也可能较高。权重越高,表示该词对当前词越重要。通过注意力权重，可以关注与当前词相关的其他词。这使得模型可以利用整个上下文的信息，不仅仅依赖当前词本身,还融入其他相关词的表达。这种融合上下文信息的能力是自注意力的优势。</p><p>计算自注意力的<strong>第五步</strong>是将每一个值向量与softmax分数相乘（准备将它们相加）。这里的直觉是保持我们想要关注的词的值不变,并淹没不相关的词(例如将它们与0.001这样的小数相乘)。</p><p><strong>第六步</strong>是对加权的价值向量求和。这将产生自注意力层在该位置的输出(对于第一个词)。</p><img src="/2023/08/20/transformer/self-attention-output.png" class="" title="img"><p>这就完成了自注意力的计算，得到的向量可以输入到前馈神经网络。然而，在实际实现中，计算以矩阵形式完成，以实现更快速的处理。现在我们已经了解了词级计算的概念，让我们来看看实际的矩阵实现。</p><h2 id="自注意力的矩阵计算">自注意力的矩阵计算</h2><p>计算自注意力的<strong>第一步</strong>是计算查询(Query)、键(Key)和值(Value)矩阵。我们通过将多个嵌入词向量concat成为矩阵X，并将其与我们训练好的权重矩阵(W<sub>Q</sub>、W<sub>K</sub>，W<sub>V</sub>)相乘来完成此操作。</p><img src="/2023/08/20/transformer/self-attention-matrix-calculation.png" class="" title="img"><p><strong>最后</strong>,由于我们处理的是矩阵,我们可以用一个公式把步骤二到六合并,来计算自注意力层的输出。</p><img src="/2023/08/20/transformer/self-attention-matrix-calculation-2.png" class="" title="img"><h2 id="多头怪兽">多头怪兽</h2><p>这篇论文通过添加一种多头注意力机制进一步改进了自注意力层。这从两个方面提高了注意力层的性能:</p><ol><li class="lvl-3"><p>它扩展了模型关注不同位置的能力。在上面的例子中，z1包含了每一个其他编码的一小部分,但它可能会被词本身主导。如果我们正在翻译这样一句话:“The animal didn’t cross the street because it was too tired”,知道“it”指的是哪个词会很有用。</p></li><li class="lvl-3"><p>它为注意力层提供了多个“表示子空间”。接下来我们会看到，使用多头注意力,我们不仅有一个，而是有多个查询/键/值权重矩阵组（Transformer使用8个注意力头,所以我们最终会为每个编码器/解码器得到8个组）。每个组都是随机初始化的。然后,，在训练后，每个组用于将输入嵌入(或来自下层编码器/解码器的向量)投影到不同的表示子空间中。</p></li></ol><img src="/2023/08/20/transformer/transformer_attention_heads_qkv.png" class="" title="img"><p>对于多头注意力，我们为每个头保留单独的Q/K/V权重矩阵，从而产生不同的Q/K/V矩阵。正如我们之前所做的，我们将X乘以W<sub>Q</sub>/W<sub>K</sub>/W<sub>V</sub>矩阵得到Q/K/V矩阵。</p><p>如果我们做与上面概述相同的自注意力计算，只是用不同的权重矩阵做8次，我们最终会得到8个不同的Z矩阵。</p><img src="/2023/08/20/transformer/transformer_attention_heads_z.png" class="" title="img"><p>这给我们提出了一个小挑战。前馈层希望得到的不是8个矩阵， 而是一个单一的矩阵(每个词一个向量)。所以我们需要一种方法来将这8个矩阵凝聚成一个单一的矩阵。</p><p>我们该如何做到这一点呢?我们连接这些矩阵，然后将它们乘以一个额外的权重矩阵W<sup>O</sup>。</p><img src="/2023/08/20/transformer/transformer_attention_heads_weight_matrix_o.png" class="" title="img"><p>这就构成了多头自注意力的全部。我意识到这涉及到大量的矩阵，让我试着将它们都放在一个视觉界面中,这样我们可以一起看到它们:</p><img src="/2023/08/20/transformer/transformer_multi-headed_self-attention-recap.png" class="" title="img"><p>既然我们已经接触了注意力头，让我们重新审视之前的例子，看看在我们对示例句子中的“it”进行编码时，不同的注意力头都关注在哪里:</p><img src="/2023/08/20/transformer/transformer_self-attention_visualization_2.png" class="" title="img"><p>当我们对“it”这个词进行编码时，一个注意力头集中在“the animal”上，而另一个注意力头则集中在“tired”上——从某种意义上说，模型对“it”这个词的表示与“the animal”和“tired”的一些表示一样。</p><p>然而，如果我们添加所有注意力头到图片中，可能会更难以解释:</p><img src="/2023/08/20/transformer/transformer_self-attention_visualization_3.png" class="" title="img"><h2 id="使用位置编码表示序列顺序">使用位置编码表示序列顺序</h2><p>到目前为止，我们描述的模型中缺少一种考虑输入序列中词顺序的方法。</p><p>为了解决这个问题，transformer会向每个输入嵌入加上一个向量。这些向量遵循模型学习的一个特定模式，它帮助模型确定每个词的位置，或者序列中不同词之间的距离。这里的直觉是,将这些值加到嵌入向量中，在它们被投影到Q/K/V向量并在点积注意力期间，为嵌入向量之间提供有意义的距离。</p><img src="/2023/08/20/transformer/transformer_positional_encoding_vectors.png" class="" title="img"><p>为了让模型了解到单词的顺序，我们添加了值遵循特定模式的位置编码向量。</p><p>如果我们假设嵌入的维度为4，实际的位置编码看起来如下:</p><img src="/2023/08/20/transformer/transformer_positional_encoding_example.png" class="" title="img"><p>这个模式可能是什么样的呢?</p><p>在下面的图中，每一行对应一个向量的位置编码。所以第一行将是我们加到输入序列中第一个词的嵌入的向量。每一行包含512个值 - 每个值介于1和-1之间。我们用不同的颜色进行了编码，使得这个模式可见。</p><img src="/2023/08/20/transformer/transformer_positional_encoding_large_example.png" class="" title="img"><p>嵌入大小为512（列）的20个字（行）的位置编码的真实示例。你可以看到看起来像是从中心一分为二。这是因为左半部分的值是由一个函数（使用正弦）生成，右半部分由另一个函数生成（使用余弦）。然后将它们连接起来已形成每个位置编码向量。</p><p>位置编码的公式在论文中有描述(第3.5节)。你可以在<code>get_timing_signal_1d()</code>中看到生成位置编码的代码。这不是位置编码的唯一可能方法。然而，它具有扩展到未知序列长度的优势（例如,如果我们训练好的模型被要求翻译长度超过训练集中任何句子的句子）。</p><p>上面显示的位置编码来自Transformer的Tensor2Tensor实现。论文中显示的方法略有不同，它没有直接连接,而是交织这两个信号。下图显示了它的样子：</p><img src="/2023/08/20/transformer/attention-is-all-you-need-positional-encoding.png" class="" title="img"><h2 id="残差连接">残差连接</h2><p>在继续讨论编码器架构之前，我们需要提到一个细节是，每个编码器中的每个子层（自注意力层、前馈全连接网络）都在其周围有一个残差连接，并且后面跟着一个Layer Norm步骤。</p><img src="/2023/08/20/transformer/transformer_resideual_layer_norm.png" class="" title="img"><p>如果我们可视化与自注意力相关的向量和Layer Norm操作，它看起来像这样:</p><img src="/2023/08/20/transformer/transformer_resideual_layer_norm_2.png" class="" title="img"><p>解码器的子层也一样。如果我们考虑一个由2个编码器和解码器堆叠的Transformer，它看起来会是这样:</p><img src="/2023/08/20/transformer/transformer_resideual_layer_norm_3.png" class="" title="img"><h2 id="解码器端">解码器端</h2><p>现在我们已经涵盖了编码器端的绝大多数概念，我们基本上也知道解码器组件的工作方式。但让我们看看它们是如何协同工作的。</p><p>编码器首先处理输入序列，然后顶层编码器的输出被转化为一组注意力向量K和V。这些将被每个解码器在其“encoder-decoder attention”层使用，该层帮助解码器关注输入序列中的适当位置:</p><img src="/2023/08/20/transformer/transformer_decoding_1.gif" class="" title="img"><p>编码阶段完成后，我们开始解码阶段。解码阶段的每个步骤输出序列的一个元素(在本例中是英语句子的翻译)。</p><p>下面的步骤会重复这个过程，直到达到一个特殊的符号，表明transformer解码器已经完成了其输出。每个步骤的输出被馈送到下一个时间步的底层解码器，解码器像编码器一样传递它们的解码结果。和我们对编码器输入所做的一样，我们解码器输入进行嵌入编码并添加位置编码来指示每个词的位置。</p><img src="/2023/08/20/transformer/transformer_decoding_2.gif" class="" title="img"><p>解码器中的自注意力层的操作方式与编码器中的略有不同:</p><p>在解码器中，自注意力层只允许关注输出序列中的先前位置。这是通过在自注意力计算的softmax步骤之前，屏蔽(设置为<code>-inf</code>)未来位置来完成的。</p><p>“encoder-decoder attention”层的工作方式与多头自注意力层类似，只不过它从下层获取Query，并从编码组件的输出中获取Key和Value。</p><p>总结解码器端的工作流程:</p><ol><li class="lvl-3"><p>解码器包含两层注意力机制：自注意力层和编码器-解码器注意力层。</p></li><li class="lvl-3"><p>自注意力层只关注当前位置之前的输出，避免使用未来信息。</p></li><li class="lvl-3"><p>编码器-解码器注意力层将编码器输出作为键和值，和当前解码器层查询交互。</p></li><li class="lvl-3"><p>通过这两层注意力，解码器可以利用输入序列和已生成序列的上下文信息。</p></li><li class="lvl-3"><p>解码器通过这种上下文注意力生成翻译输出，依次生成序列,实现神经机器翻译。</p></li></ol><h2 id="最终线性层和softmax层">最终线性层和softmax层</h2><p>解码器端输出一个浮点数向量。我们如何将其转化为词呢？这是最终线性层后面连接的softmax层的工作。</p><p>线性层是一个简单的全连接神经网络，它将解码器端产生的向量投影到一个的更大的向量中，称为logits向量。</p><p>假设我们的模型从训练集中学习到了10,000个唯一的英语词汇表（模型的“输出词汇表”）。这将使logits向量的宽度为10,000个单元格 - 每个单元格对应一个唯一词汇的得分。这就是我们对线性层之后模型输出的解释。</p><p>然后softmax层将那些得分转化为概率（全部为正,全部加和为1.0)，选择概率最高的单元格，并产生与其相关的词作为该时间步的输出。</p><img src="/2023/08/20/transformer/transformer_decoder_output_softmax.png" class="" title="img"><p>总结一下从解码器到输出词的转换过程:</p><ol><li class="lvl-3"><p>解码器输出一个浮点向量。</p></li><li class="lvl-3"><p>通过全连接层映射到更高维的logits向量，每个维度表示一个词的得分。</p></li><li class="lvl-3"><p>对logits向量做softmax,得到单词概率分布。</p></li><li class="lvl-3"><p>选取概率最大的单词作为当前时间步的输出。</p></li><li class="lvl-3"><p>不断重复这一过程,生成输出序列。</p></li><li class="lvl-3"><p>线性层和softmax层起到分类作用,实现seq2seq模型的解码。</p></li></ol><p>这就是Transformer将编码器向量转变为翻译输出的最后一步。</p><h2 id="训练回顾">训练回顾</h2><p>现在我们已经介绍了Transformer的整个前向传播过程，回顾一下模型训练会有帮助。</p><p>在训练过程中，一个未训练的模型会经历完全相同的前向传播。但是由于我们在标注训练集上训练它，我们可以将它的输出与实际的正确输出进行比较。</p><p>为了可视化这个过程，让我们假设我们的输出词汇表只包含6个词（“a”,“am”,“i”,“thanks”,“student&quot;和”<eos>&quot;（表示句子结束））。</p><img src="/2023/08/20/transformer/vocabulary.png" class="" title="img"><p>在我们开始训练之前的预处理阶段，我们的模型输出词汇表就已经创建。</p><p>一旦我们定义了输出词汇表，我们就可以使用具有相同宽度的向量来表示词汇表中的每个词。这也称为独热编码。例如，我们可以使用以下向量来表示“am”这个词:</p><img src="/2023/08/20/transformer/one-hot-vocabulary-example.png" class="" title="img"><p>在这个回顾之后，让我们讨论模型的损失函数 - 训练阶段优化的指标，以获得一个经过训练和极其准确的模型。</p><h2 id="损失函数"><strong>损失函数</strong></h2><p>假设我们正在训练模型，并且我们处于训练阶段的第一步，用一个简单的例子进行训练 - 将“merci”翻译成“thanks”。</p><p>这意味着我们希望输出是一个概率分布，指示单词“thanks”。但是由于这个模型还没有训练,这不太可能立即发生。</p><img src="/2023/08/20/transformer/transformer_logits_output_and_label.png" class="" title="img"><p>由于模型的参数(权重)都是随机初始化的，所以(未训练的)模型为每个单元格/词产生具有任意值的概率分布。我们可以将其与实际输出进行比较，然后使用反向传播调整模型的所有权重，使输出更接近期望输出。</p><p>你如何比较两个概率分布呢？我们简单地将一个减去另一个。更多详情，请参阅 <a href="https://colah.github.io/posts/2015-09-Visual-Information/">cross-entropy</a> 和 <a href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained">Kullback–Leibler divergence</a>。</p><p>但请注意，这是一个过于简化的例子。我们会使用长度大于一的句子。例如：输入“je suis étudiant”，期望输出：“i am a student”。这实际上意味着我们希望模型逐步输出概率分布，其中:</p><ul class="lvl-0"><li class="lvl-2"><p>每个概率分布由vocab_size宽的向量表示（在我们的简易例子中是6，但实际是3万或5万这样的数字）</p></li><li class="lvl-2"><p>第一个概率分布在与单词“i”相关的单元上概率最高</p></li><li class="lvl-2"><p>第二个概率分布在与单词“am”相关的单元上概率最高</p></li><li class="lvl-2"><p>以此类推。直到第五个输出分布指示“<end of sentence>”符号，它在10,000元素词汇表中也有一个相关的单元。</p></li></ul><img src="/2023/08/20/transformer/output_target_probability_distributions.png" class="" title="img"><p>在足够长的时间内对足够大的数据集进行训练后，我们希望产生的概率分布如下所示:</p><img src="/2023/08/20/transformer/output_trained_model_probability_distributions.png" class="" title="img"><p>希望在训练后，模型会输出我们期望的正确翻译。当然，如果这个短语是训练集的一部分,这并不是真正的指标（参见：<a href="https://www.youtube.com/watch?v=TIgfjmp-4BA">cross validation</a>）。注意，即使不太可能是该时间步的输出，每个位置也会获得一点概率。这是softmax的非常有用的属性，可以有助于训练过程。</p><p>现在，因为模型逐个产生输出，我们可以假设模型正在从该概率分布中选择概率最高的单词，并忽略其余部分，这是一种贪婪解码。另一种方法是保留前两个词（例如“I”和“a”），然后在下一步中，对模型运行两次：一次假设第一输出位置是“I” ,另一次假设第一输出位置是“a”，哪个版本考虑位置#1和#2时产生的误差更小，就保留哪个。我们对位置#2和#3重复此过程…等等。这种方法称为“束搜索”，在我们的示例中，beam_size为2（意味着在任何时候都保留两个部分假设（未完成的翻译）在内存中），top_beams也为2（意味着我们将返回两个翻译）。这些都是你可以尝试的超参数。</p><h2 id="展望">展望</h2><p>我希望这对您开启与Transformer的主要概念的破冰之旅有所帮助。如果您想深入了解，我建议您采取以下后续步骤:</p><ul class="lvl-0"><li class="lvl-2"><p>阅读 <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> l论文，Transformer博客 (<a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Transformer: A Novel Neural Network Architecture for Language Understanding</a>)，和 <a href="https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html">Tensor2Tensor announcement</a>。</p></li><li class="lvl-2"><p>观看 <a href="https://www.youtube.com/watch?v=rBCqOTEfxvg">Łukasz Kaiser的演讲</a> ，详细介绍该模型以及细节。</p></li><li class="lvl-2"><p>使用 <a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb">Tensor2Tensor仓库提供的 Jupyter Notebook</a>。</p></li><li class="lvl-2"><p>探索<a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor仓库</a>。</p></li></ul><p>后续工作：</p><ul class="lvl-0"><li class="lvl-2"><p><a href="https://arxiv.org/abs/1706.03059">Depthwise Separable Convolutions for Neural Machine Translation</a></p></li><li class="lvl-2"><p><a href="https://arxiv.org/abs/1706.05137">One Model To Learn Them All</a></p></li><li class="lvl-2"><p><a href="https://arxiv.org/abs/1801.09797">Discrete Autoencoders for Sequence Models</a></p></li><li class="lvl-2"><p><a href="https://arxiv.org/abs/1801.10198">Generating Wikipedia by Summarizing Long Sequences</a></p></li><li class="lvl-2"><p><a href="https://arxiv.org/abs/1802.05751">Image Transformer</a></p></li><li class="lvl-2"><p><a href="https://arxiv.org/abs/1804.00247">Training Tips for the Transformer Model</a></p></li><li class="lvl-2"><p><a href="https://arxiv.org/abs/1803.02155">Self-Attention with Relative Position Representations</a></p></li><li class="lvl-2"><p><a href="https://arxiv.org/abs/1803.03382">Fast Decoding in Sequence Models using Discrete Latent Variables</a></p></li><li class="lvl-2"><p><a href="https://arxiv.org/abs/1804.04235">Adafactor: Adaptive Learning Rates with Sublinear Memory Cost</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>torch常用函数</title>
    <link href="/2023/08/20/torch%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"/>
    <url>/2023/08/20/torch%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<ol><li class="lvl-3"><p>squeeze&amp;unsqueeze</p><ul class="lvl-2"><li class="lvl-6"><p>torch.squeeze(input, dim=None, out=None) → Tensor</p><ul class="lvl-4"><li class="lvl-10">input (Tensor) – the input tensor.</li><li class="lvl-10">dim (int, optional) – if given, the input will be squeezed only in this dimension</li><li class="lvl-10">out (Tensor, optional) – the output tensor.</li></ul><p>去除维度为1的维度</p></li><li class="lvl-6"><p>torch.unsqueeze(input, dim) → Tensor</p><ul class="lvl-4"><li class="lvl-10">input (Tensor) – the input tensor.</li><li class="lvl-10">dim (int) – the index at which to insert the singleton dimension</li></ul><p>在指定维度增加维度为1的维度</p></li></ul></li><li class="lvl-3"><p>argmax</p><p>torch.argmax(input, dim=None, keepdim=False) → LongTensor</p><ul class="lvl-2"><li class="lvl-6"><p>input (Tensor) – the input tensor.</p></li><li class="lvl-6"><p>dim (int, optional) – the dimension to reduce. If None, the argmax of the flattened input is returned.</p></li><li class="lvl-6"><p>keepdim (bool) – whether the output tensor has dim retained or not. Ignored if dim=None.</p></li></ul><p>返回指定维度上最大值的索引</p></li><li class="lvl-3"><p>detach</p><p>torch.Tensor.detach() → Tensor</p><p>Returns a new Tensor, detached from the current graph.</p><p>The result will never require gradient.</p><p>返回一个新的Tensor，从当前图中分离出来。</p></li><li class="lvl-3"><p>repeat_interleave</p><p>torch.repeat_interleave(input, repeats, dim=None) → Tensor</p><ul class="lvl-2"><li class="lvl-6"><p>input (Tensor) – the input tensor.</p></li><li class="lvl-6"><p>repeats (int or Tensor) – The number of repetitions for each element. repeats is broadcasted to fit the shape of the given axis.</p></li><li class="lvl-6"><p>dim (int, optional) – the axis along which to repeat values. By default, use the flattened input array, and return a flat output array.</p></li></ul><p>Repeat elements of a tensor.</p><ul class="lvl-2"><li class="lvl-6"><p>If repeats is an int, then tensor is repeated repeats times along given axis.</p></li><li class="lvl-6"><p>If repeats is a Tensor, then tensor must be 1-dimensional and repeats must be broadcastable to the rest of the shape of tensor. Each element of tensor is repeated repeats times along given axis.</p></li></ul><p>在指定维度上重复张量的元素</p></li><li class="lvl-3"><p>repeat</p><p>torch.repeat(input, repeats) → Tensor</p><ul class="lvl-2"><li class="lvl-6"><p>input (Tensor) – the input tensor.</p></li><li class="lvl-6"><p>repeats (tuple of python:ints) – The number of times to repeat this tensor along each dimension</p></li></ul><p>Repeat elements of a tensor.</p><ul class="lvl-2"><li class="lvl-6"><p>If repeats is an int, then tensor is repeated repeats times along each dimension.</p></li><li class="lvl-6"><p>If repeats is a tuple, then tensor must be 1-dimensional and repeats must be of length equal to the number of dimensions of tensor. Each element of tensor is repeated repeats[i] times along dimension i.</p></li></ul><p>在每个维度上重复张量的元素</p></li><li class="lvl-3"><p>transpose</p><p>torch.transpose(input, dim0, dim1) → Tensor<br>交换两个维度</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>输入url全过程</title>
    <link href="/2023/08/05/%E8%BE%93%E5%85%A5url%E5%85%A8%E8%BF%87%E7%A8%8B/"/>
    <url>/2023/08/05/%E8%BE%93%E5%85%A5url%E5%85%A8%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<ol><li class="lvl-3"><p>用户在浏览器中输入url，浏览器接收到url</p></li><li class="lvl-3"><p>浏览器查找当前url是否存在缓存，并比较缓存是否过期，如果缓存有效，跳转到转码步骤，否则跳转到DNS解析步骤</p></li><li class="lvl-3"><p>浏览器通过DNS解析url，获得协议名、域名、端口号。</p><p>DNS解析过程：</p><ol><li class="lvl-7"><p>检查本地hosts文件是否有这个域名映射，如果有，直接返回结果，完成域名解析。</p></li><li class="lvl-7"><p>如果没有，浏览器会检查本地DNS缓存是否有这个域名映射，如果有，直接返回结果，完成域名解析。</p></li><li class="lvl-7"><p>如果没有，浏览器会检查本地DNS服务器是否有这个域名映射，如果有，直接返回结果，完成域名解析。</p></li><li class="lvl-7"><p>如果没有，本地DNS服务器会向根域名服务器发起请求，根域名服务器会返回一个所查询域名的主域名服务器的地址，本地DNS服务器再向主域名服务器发起请求，主域名服务器会返回一个所查询域名的权威域名服务器的地址，本地DNS服务器再向权威域名服务器发起请求，权威域名服务器会返回一个所查询域名的IP地址，本地DNS服务器再向浏览器返回查询结果，完成域名解析。</p></li></ol></li><li class="lvl-3"><p>浏览器向服务器发起TCP连接，与服务器建立TCP三次握手，建立TCP连接。</p><p>TCP三次握手过程：</p><ol><li class="lvl-7"><p>客户端向服务器发送一个SYN=1报文，报文中包含自己的初始序列号seq=x，客户端进入SYN_SEND状态。</p></li><li class="lvl-7"><p>服务器收到SYN报文，向客户端发送一个SYN=1，ACK=1的报文，报文中包含自己的初始序列号seq=y，确认号ack=x+1，服务器进入SYN_RECV状态。</p></li><li class="lvl-7"><p>客户端收到服务器的报文，向服务器发送一个ACK=1的报文，报文中包含确认号ack=y+1，客户端进入ESTABLISHED状态，服务器收到客户端的报文，进入ESTABLISHED状态。</p></li></ol></li><li class="lvl-3"><p>浏览器向服务器发送HTTP请求，请求数据包括：</p><p>TCP连接建立后，浏览器构建HTTP请求数据包，请求数据包包括请求行、请求头部、请求正文，并把和该域名相关的Cookie信息附加到请求头部，然后向服务器发送HTTP请求。如果是HTTPS请求，还需要额外的SSL握手过程。</p></li><li class="lvl-3"><p>服务器接收到HTTP请求，根据路径参数，经过后端处理，返回HTTP响应。</p></li><li class="lvl-3"><p>关闭浏览器与服务器之间的连接。</p><ol><li class="lvl-7">客户端向服务器发送一个FIN=1的报文，报文中包含序列号seq=u，客户端进入FIN_WAIT_1状态。</li><li class="lvl-7">服务端收到FIN报文，向客户端发送一个ACK=1的报文，报文中包含确认号ack=u+1，服务端进入CLOSE_WAIT状态。</li><li class="lvl-7">服务端向客户端发送一个FIN=1的报文，报文中包含序列号seq=v，确认号ack=u+1，服务端进入LAST_ACK状态。</li><li class="lvl-7">客户端收到FIN报文，向服务端发送一个ACK=1的报文，报文中包含确认号ack=v+1，客户端进入TIME_WAIT状态，等待2MSL后，客户端进入CLOSED状态</li><li class="lvl-7">服务端收到ACK报文，进入CLOSED状态。</li></ol></li></ol>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Zotero:文献管理</title>
    <link href="/2023/06/26/Zotero-%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/"/>
    <url>/2023/06/26/Zotero-%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/</url>
    
    <content type="html"><![CDATA[<ul class="lvl-0"><li class="lvl-2"><p>开源</p></li><li class="lvl-2"><p>支持WebDAV同步</p></li><li class="lvl-2"><p>强大的第三方插件系统</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>git基本使用</title>
    <link href="/2023/06/24/git%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/06/24/git%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="Git分布式版本控制工具">Git分布式版本控制工具</h2><h3 id="Git简介">Git简介</h3><p>Git是用C语言开发的分布式版本控制系统，所谓版本控制系统，就是可以储存一个文件在不同时间的版本，记录每次文件的改动，可以根据需要，随时切换到之前的版本(比如在编写Word文档的过程中，能记录下你每一次保存下来的记录，如果你对于现在的修改不满意，就可以回退到之前保存的版本)。下面是Git的一些基础：</p><ul class="lvl-0"><li class="lvl-2"><p>直接记录快照，而非差异比较<br>Git 把数据看作是对小型文件系统的一组快照。 每次提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。 为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 快照流。</p></li><li class="lvl-2"><p>近乎所有操作都是本地执行在 Git 中的绝大多数操作都只需要访问本地文件和资源，一般不需要来自网络上其它计算机的信息。</p></li><li class="lvl-2"><p>Git 保证完整性<br>Git 中所有数据在存储前都计算校验和，然后以校验和来引用。不可能在 Git 不知情时更改任何文件内容或目录内容。</p></li><li class="lvl-2"><p>Git 一般只添加数据你执行的 Git 操作，几乎只往 Git 数据库中增加数据。 很难让 Git 执行任何不可逆操作，或者让它以任何方式清除数据。 同别的 VCS 一样，未提交更新时有可能丢失或弄乱修改的内容；但是一旦你提交快照到 Git 中，就难以再丢失数据，特别是如果你定期的推送数据库到其它仓库的话。</p></li><li class="lvl-2"><p>Git只能跟踪文本文件的改动<br>Git只能跟踪文本文件的改动，比如TXT文件、网页、程序代码等等。关于二进制文件，可以由Git进行管理，但是无法跟踪文件的变化。</p></li></ul><h3 id="Git安装">Git安装</h3><h4 id="Linux安装">Linux安装</h4><p>如果你想在 Linux 上用二进制安装程序来安装 Git，可以使用发行版包含的基础软件包管理工具来安装。 如果以 Fedora 上为例，你可以使用 yum：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo yum install git<br></code></pre></td></tr></table></figure><p>如果你在基于 Debian 的发行版上，请尝试用 apt-get：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo apt-get install git<br></code></pre></td></tr></table></figure><h4 id="Windows安装">Windows安装</h4><p>通过Git官网下载，一步步安装即可。</p><h3 id="Git配置文件位置">Git配置文件位置</h3><p>Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：</p><ol><li class="lvl-3"><p>/etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。</p></li><li class="lvl-3"><p>~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。</p></li><li class="lvl-3"><p>当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。</p></li></ol><p>每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。</p><h3 id="配置用户信息">配置用户信息</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 配置全局用户名和邮箱</span><br>git config --global user.name <span class="hljs-string">&quot;Your Name&quot;</span><br>git config --global user.email <span class="hljs-string">&quot;email@example.com&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 配置当前仓库用户名和邮箱</span><br>git config user.name <span class="hljs-string">&quot;gitlab’s Name&quot;</span> <br>git config user.email <span class="hljs-string">&quot;gitlab@xx.com&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git config --list   <span class="hljs-comment"># 查看配置列表</span><br></code></pre></td></tr></table></figure><h3 id="创建版本库">创建版本库</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">mkdir</span> learngit      <span class="hljs-comment"># 创建文件夹</span><br><span class="hljs-built_in">cd</span> learngit         <span class="hljs-comment"># 切换到新建的文件夹</span><br>git init            <span class="hljs-comment"># 创建一个空的Git仓库或重新初始化已有仓库</span><br></code></pre></td></tr></table></figure><h3 id="Git中文件的三种状态">Git中文件的三种状态</h3><p>Git中的文件存在三种状态，已提交（committed）、已修改（modified）和已暂存（staged）。</p><ul class="lvl-0"><li class="lvl-2"><p>已提交(committed): 表示数据已经安全的保存在本地数据库中。</p></li><li class="lvl-2"><p>已修改(modified): 表示修改了文件，但还没保存到数据库中。</p></li><li class="lvl-2"><p>已暂存(staged): 表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。</p></li></ul><p>由此引入 Git 项目中三个工作区域的概念: Git 仓库、工作目录以及暂存区域。</p><ul class="lvl-0"><li class="lvl-2"><p>工作目录(Working Directory): 工作目录是对项目的某个版本独立提取出来的内容。这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。</p></li><li class="lvl-2"><p>暂存区域(Staging Area): 暂存区域是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作&quot;索引&quot;，不过一般说法还是叫暂存区域。</p></li><li class="lvl-2"><p>Git仓库(Repository): Git 仓库目录是 Git 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，拷贝的就是这里的数据。</p></li></ul><p>如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。</p><img src="/2023/06/24/git%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/image.png" class="" title="Alt text"><h3 id="查看工作目录当前状态">查看工作目录当前状态</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 查看状态报告</span><br>git status<br><span class="hljs-comment"># 更为紧凑的格式输出</span><br>git status -s<br>git status --short<br></code></pre></td></tr></table></figure><h3 id="跟踪新文件">跟踪新文件</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 添加内容到暂存区域(.git文件夹中index文件)</span><br>git add &lt;file&gt;<br><span class="hljs-comment"># 将当前目录所有文件添加到暂存区域</span><br>git add .<br><span class="hljs-comment"># 当前项目下的所有更改</span><br>git add --all <br></code></pre></td></tr></table></figure><p>可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等</p><h3 id="查看已暂存和未暂存的修改">查看已暂存和未暂存的修改</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 比较工作目录中当前文件和暂存区域快照之间的差异，也就是修改之后还没有暂存起来的变化内容。</span><br>git diff<br><span class="hljs-comment"># 比较暂存区域和本地仓库之间的差异，也就是暂存之后还未提交起来的变化内容</span><br>git diff --cached<br><span class="hljs-comment"># Git 1.6.1 及更高版本查看已暂存的将要添加到下次提交里的内容</span><br>git diff --staged<br></code></pre></td></tr></table></figure><h3 id="提交修改">提交修改</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh">git commit <br><span class="hljs-comment"># 将提交信息与命令放在同一行</span><br>git commit -m <span class="hljs-string">&quot;message&quot;</span><br><span class="hljs-comment"># 跳过使用暂存区域，自动把所有已经跟踪过的文件暂存起来一并提交</span><br>git commit -a -m <span class="hljs-string">&quot;added new benchmarks&quot;</span><br></code></pre></td></tr></table></figure><h3 id="移除文件">移除文件</h3><p>要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 简单的从工作目录中移除文件</span><br><span class="hljs-built_in">rm</span> &lt;file&gt;<br><span class="hljs-comment"># 删除未暂存的文件，并记录此次移除文件的操作</span><br>git <span class="hljs-built_in">rm</span> &lt;file&gt; <br><span class="hljs-comment"># 将文件从Git仓库中移除，但是仍保留在当前工作目录中</span><br>git <span class="hljs-built_in">rm</span> --cached &lt;file&gt;<br></code></pre></td></tr></table></figure><h3 id="移动文件">移动文件</h3><p>Git不会显式跟踪文件移动操作，如果重命名了某个文件，仓库中存储的元数据并不会体验出这是一次改名操作。如果直接修改文件名称，使用<code>git status</code>命令后，会显示如下信息。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sh">On branch master<br>Changes not staged <span class="hljs-keyword">for</span> commit:<br>(use <span class="hljs-string">&quot;git add/rm &lt;file&gt;...&quot;</span> to update what will be committed)<br>(use <span class="hljs-string">&quot;git restore &lt;file&gt;...&quot;</span> to discard changes <span class="hljs-keyword">in</span> working directory)<br>        deleted:    oldfilename<br><br>Untracked files:<br>(use <span class="hljs-string">&quot;git add &lt;file&gt;...&quot;</span> to include <span class="hljs-keyword">in</span> what will be committed)<br>    newfilename<br></code></pre></td></tr></table></figure><p>接着使用<code>git add .</code>将修改记录添加至暂存区，此时再使用<code>git status</code>，可以看到Git成功识别到了改名操作。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh">On branch master<br>Changes to be committed:<br>(use <span class="hljs-string">&quot;git restore --staged &lt;file&gt;...&quot;</span> to unstage)<br>        renamed:    oldfilename -&gt; newfilename<br></code></pre></td></tr></table></figure><p>Git给出了一个mv命令，在需要对文件进行改名时，可以使用<code>git mv file_from file_to</code>，使用此命令修改文件名字后，与上面的效果相同。其实，运行 git mv 就相当于运行了下面三条命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">mv</span> file_from file_to<br>git <span class="hljs-built_in">rm</span> file_from<br>git add file_to<br></code></pre></td></tr></table></figure><h3 id="查看提交历史">查看提交历史</h3><p>使用最简单而又有效的工具是<code>git log</code>命令。在项目中运行<code>git log</code>，可以看到下面的输出：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">log</span><br>commit ca82a6dff817ec66f44342007202690a93763949<br>Author: Scott Chacon &lt;schacon@gee-mail.com&gt;<br>Date:   Mon Mar 17 21:52:11 2008 -0700<br><br>    changed the version number<br><br>commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7<br>Author: Scott Chacon &lt;schacon@gee-mail.com&gt;<br>Date:   Sat Mar 15 16:40:33 2008 -0700<br><br>    removed unnecessary <span class="hljs-built_in">test</span><br><br>commit a11bef06a3f659402fe7563abf99ad00de2209e6<br>Author: Scott Chacon &lt;schacon@gee-mail.com&gt;<br>Date:   Sat Mar 15 10:31:28 2008 -0700<br><br>    first commit<br></code></pre></td></tr></table></figure><p>下面是一些查看提交历史的简单命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 默认不用任何参数会按提交时间列出所有的更新，最近的更新排在最上面。</span><br>git <span class="hljs-built_in">log</span><br><span class="hljs-comment"># -p 用来显示每次提交的内容差异，可以加上 -2 来仅显示最近两次提交。</span><br>git <span class="hljs-built_in">log</span> -p -2<br><span class="hljs-comment"># 如果你想看到每次提交的简略的统计信息，可以使用 --stat 选项。</span><br>git <span class="hljs-built_in">log</span> --<span class="hljs-built_in">stat</span><br><span class="hljs-comment"># --pretty选项可以指定使用不同于默认格式的方式展示提交历史。</span><br><span class="hljs-comment"># 用 oneline 将每个提交放在一行显示，查看的提交数很大时非常有用。 </span><br>git <span class="hljs-built_in">log</span> --pretty=oneline<br><span class="hljs-comment"># 另外还有 short，full 和 fuller 可以用，展示的信息或多或少有些不同。</span><br><span class="hljs-comment"># format，可以定制要显示的记录格式，还有很多其他选项，可以查看 Git 文档。</span><br>git <span class="hljs-built_in">log</span> --pretty=format:<span class="hljs-string">&quot;%h - %an, %ar : %s&quot;</span><br></code></pre></td></tr></table></figure><h3 id="版本回退">版本回退</h3><ol><li class="lvl-3"><p>HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令<code>git reset --hard commit_id</code>。</p></li><li class="lvl-3"><p>穿梭前，用<code>git log</code>可以查看提交历史，以便确定要回退到哪个版本。</p></li><li class="lvl-3"><p>要重返未来，用<code>git reflog</code>查看命令历史，以便确定要回到未来的哪个版本。</p></li></ol><h3 id="撤销操作">撤销操作</h3><div class="tips"><p><strong>提示</strong><br><code>git checkout</code> 这个命令承担了太多职责，既被用来切换分支，又被用来恢复工作区文件，对用户造成了很大的认知负担。Git社区发布的Git2.23版本中，引入了两个新命令 <code>git switch</code> 和 <code>git restore</code>，用以替代现在的 <code>git checkout</code>。换言之，<code>git checkout</code> 将逐渐退出历史舞台。</p></div><h4 id="重新提交-Git-仓库">重新提交(Git 仓库)</h4><p>在已经提交后，发现漏掉几个文件没有添加，或者提交信息写错了。此时可以运行带有<code>--amend</code>提交命令尝试重新提交。最终只会有一个提交，第二次提交将替代第一次提交的结果。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">git commit --amend<br>git commit --amend -m  <span class="hljs-string">&quot;message&quot;</span><br></code></pre></td></tr></table></figure><h4 id="取消暂存的文件-暂存区域">取消暂存的文件(暂存区域)</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 丢弃暂存区的修改，重新放回工作区。相当于撤销git add 操作，不影响上一次commit后对本地文件的修改，包括对文件的操作，如添加文件、删除文件。</span><br>git reset HEAD &lt;file_name&gt; <br><span class="hljs-comment"># 清空暂存区，重置工作区的版本至上一次提交前</span><br>git reset –hard HEAD <br><span class="hljs-comment"># 恢复暂存区的所有文件到工作区</span><br>git checkout .<br></code></pre></td></tr></table></figure><h4 id="取消对文件的修改-工作目录">取消对文件的修改(工作目录)</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 将暂存区的修改重新放回工作区（包括对文件自身的操作，如添加文件、删除文件）</span><br>git restore --staged &lt;file_name&gt; <br><span class="hljs-comment"># 丢弃文件在工作目录的修改（不包括对文件自身的操作，如添加文件、删除文件）</span><br>git restore &lt;file_name&gt; <br></code></pre></td></tr></table></figure><img src="/2023/06/24/git%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/image-2.png" class="" title="Alt text"><h3 id="忽略文件">忽略文件</h3><p>文件 .gitignore 的格式规范如下：</p><ol><li class="lvl-3"><p>所有空行或者以 # 开头的行都会被 Git 忽略。</p></li><li class="lvl-3"><p>可以使用标准的 glob 模式匹配。</p></li><li class="lvl-3"><p>匹配模式可以以（/）开头防止递归。</p></li><li class="lvl-3"><p>匹配模式可以以（/）结尾指定目录。</p></li><li class="lvl-3"><p>要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。</p></li></ol><p>所谓的 glob 模式是指 sh 所使用的简化了的正则表达式。 星号 (*) 匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）；问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号 (**) 表示匹配任意中间目录，比如a/**/z 可以匹配 a/z, a/b/z 或 a/b/c/z等。</p><h3 id="远程仓库">远程仓库</h3><p>远程仓库是指托管在因特网或其他网络中的你的项目的版本库。可以同时拥有多个远程仓库，这些仓库部分拥有只读权限，部分仓库拥有读写权限。 与他人协作涉及管理远程仓库以及根据需要推送或拉取数据。 管理远程仓库包括了解如何添加远程仓库、移除无效的远程仓库、管理不同的远程分支并定义它们是否被跟踪等等。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 查看远程仓库</span><br><span class="hljs-comment"># 列出指定的每一个远程服务器的简写。</span><br>git remote<br><span class="hljs-comment"># 显示需要读写远程仓库使用的 Git 保存的简写与其对应的 URL。</span><br>git remote -v<br><span class="hljs-comment"># 查看某一个远程仓库的更多信息， 包含远程仓库的 URL 与跟踪分支的信息、拉取到的所有远程引用等等。</span><br>git remote show remote-name<br><br><span class="hljs-comment"># 添加远程仓库</span><br><span class="hljs-comment"># 添加一个新的远程 Git 仓库，同时指定一个轻松引用的简写</span><br>git remote add shortname remote-url<br><br><span class="hljs-comment"># 远程仓库的重命名</span><br>git remote rename oldname newname <span class="hljs-comment"># 修改远程仓库的简写名</span><br><br><span class="hljs-comment"># 移除远程仓库</span><br>git remote <span class="hljs-built_in">rm</span> remote-name<br><br><span class="hljs-comment"># 将某个远程仓库的更新全部取回本地,并不会自动合并或修改你当前的工作</span><br>git fetch remote-name<br><span class="hljs-comment"># 从远程仓库取回特定分支的更新</span><br>git fetch remote-name branch-name<br><br><span class="hljs-comment"># 将远程主机的某个分支的更新取回，并与本地指定的分支合并</span><br>git pull remote-name remote-branch:local-branch<br><br><span class="hljs-comment"># 推送到远程仓库，必须将先前的推送拉取下来并合并后才可以推送</span><br>git push remote-name branch-name<br></code></pre></td></tr></table></figure><h3 id="打标签">打标签</h3><p>Git 可以给历史中的某一个提交打上标签，以示重要。</p><h4 id="查看标签">查看标签</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">git tag                 <span class="hljs-comment"># 列出已有标签，按照字母顺序</span><br>git tag -l <span class="hljs-string">&quot;regex&quot;</span>      <span class="hljs-comment"># 使用特定的模式查找标签</span><br>git show &#123;tag-name&#125;     <span class="hljs-comment"># 查看某个具体标签的信息</span><br></code></pre></td></tr></table></figure><h4 id="标记标签">标记标签</h4><p>Git 使用两种主要类型的标签：轻量标签（lightweight）与附注标签（annotated）。</p><p>轻量标签（lightweight tag）仅仅是一个指向特定提交的引用，它不会存储任何额外的信息。创建轻量标签的命令如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git tag &#123;标签名&#125; &#123;提交ID&#125;<br></code></pre></td></tr></table></figure><p>附注标签（annotated tag）是存储在Git数据库中的一个完整对象，它有一个标签名，标签信息，标签签名等信息。创建附注标签的命令如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git tag -a &#123;标签名&#125; -m <span class="hljs-string">&quot;&#123;标签信息&#125;&quot;</span> &#123;提交ID&#125;<br></code></pre></td></tr></table></figure><p><strong>注意</strong>：创建标签时，如果不指定提交ID，默认会使用当前所在分支的最新提交作为标签指向的提交。</p><h4 id="推送标签">推送标签</h4><p>默认情况下，git push命令不会将标签推送到远程服务器，需要使用以下命令将标签推送到远程服务器：</p><p>将标签推送到远程服务器</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git push origin &#123;标签名&#125;<br></code></pre></td></tr></table></figure><p>要一次性推送所有本地标签到远程服务器</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git push origin --tags<br></code></pre></td></tr></table></figure><h4 id="删除标签">删除标签</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git tag -d &#123;标签名&#125;<br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git push origin :refs/tags/&#123;标签名&#125;<br></code></pre></td></tr></table></figure><h3 id="Git-分支">Git 分支</h3><p>为何 Git 的分支模型如此出众呢？ Git 处理分支的方式可谓是难以置信的轻量，创建新分支这一操作几乎能在瞬间完成，并且在不同分支之间的切换操作也是一样便捷。Git 鼓励在工作流程中频繁地使用分支与合并，哪怕一天之内进行许多次。</p><h4 id="分支切换">分支切换</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git checkout &#123;分支名&#125;<br></code></pre></td></tr></table></figure><h4 id="分支的创建与合并">分支的创建与合并</h4><p>在工作时，经常会经历如下步骤：</p><ol><li class="lvl-3"><p>开发某个项目。</p></li><li class="lvl-3"><p>为实现某个新的需求，创建一个分支。</p></li><li class="lvl-3"><p>在这个分支上开展工作。</p></li></ol><p>正在此时，可能发布的线上版本有一个严重的问题需要紧急修补。将按照如下方式进行处理：</p><ol><li class="lvl-3"><p>切换到线上分支（production branch）。</p></li><li class="lvl-3"><p>为这个紧急任务新建一个修补分支，并在其中修复它。</p></li><li class="lvl-3"><p>在测试通过之后，切换回线上分支，然后合并这个修补分支，最后将改动推送到线上分支。</p></li><li class="lvl-3"><p>切换回最初工作的分支，继续工作。</p></li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 创建一个新的分支</span><br>git branch &#123;分支名&#125; <br><span class="hljs-comment"># 创建一个新的分支并切换到该分支上</span><br>git checkout -b &#123;分支名&#125;    <br></code></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-comment"># 删除分支</span><br>git branch -d &#123;分支名&#125;  <br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>编程工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Git</tag>
      
      <tag>Github</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第三方登陆流程</title>
    <link href="/2023/06/24/%E7%AC%AC%E4%B8%89%E6%96%B9%E7%99%BB%E9%99%86%E6%B5%81%E7%A8%8B/"/>
    <url>/2023/06/24/%E7%AC%AC%E4%B8%89%E6%96%B9%E7%99%BB%E9%99%86%E6%B5%81%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>Web设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>AlexNet</title>
    <link href="/2023/06/24/AlexNet/"/>
    <url>/2023/06/24/AlexNet/</url>
    
    <content type="html"><![CDATA[<h2 id="引言">引言</h2><p>2012年，Alex Krizhevsky等人提出了AlexNet网络，并以很大的优势赢得了ImageNet2012图像识别挑战赛的冠军。同时，AlexNet是第⼀个在⼤规模视觉竞赛中击败传统计算机视觉模型的⼤型神经⽹络。</p><h2 id="网络结构">网络结构</h2><p>AlexNet由5个卷积层、3个池化Pooling层和3个全连接层构成。</p><h2 id="Encoder-Decoder架构">Encoder-Decoder架构</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decoder</span>(nn.Module)<br>    <span class="hljs-string">&quot;&quot;&quot;编码器-解码器结构的基本解码器接口&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(Decoder, self).__init__(**kwargs)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self, enc_outputs, *args</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X, state</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机视觉</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>即时通讯</title>
    <link href="/2023/06/22/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/"/>
    <url>/2023/06/22/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>实现即时通讯常见的有四种方式，分别是：轮询、长轮询(comet)、长连接(SSE)、WebSocket。</p><h2 id="介绍">介绍</h2><h3 id="轮询">轮询</h3><p>拉模式，不管服务端数据有无更新，客户端利用Ajex定时发送请求拉取一次数据，可能有更新数据返回，也可能什么都没有。<br><strong>优点</strong>: 后端编码简单<br><strong>缺点</strong>: 数据延迟、消耗资源过大、请求次数太多</p><img src="/2023/06/22/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/image.png" class="" title="轮询"><h3 id="长轮询-comet">长轮询(comet)</h3><p>客户端发起长轮询，如果服务端的数据没有发生变更，会hold住请求，直到服务端的数据发生变化，或者等待一定时间超时才会返回。返回后，客户端再发起下一次长轮询请求监听。<br><strong>优点</strong>:</p><ul class="lvl-0"><li class="lvl-2"><p>相较于轮询基本不存在消息延迟，请求次数降低很多</p></li><li class="lvl-2"><p>长轮询是在 XMLHttpRequest 之后实现的，它几乎得到了设备的普遍支持，因此通常很少需要有进一步的备选方案，在很多场景下，可以作为即时通信的最简单实现方案和兜底兼容方案。</p></li></ul><p><strong>缺点</strong>:服务器一直保持连接会消耗资源，需要同时维护多个线程，而服务器所能承载的 TCP 连接是有上限的，所以这种轮询很容易导致连接上限。</p><img src="/2023/06/22/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/image-2.png" class="" title="长轮询"><h3 id="长连接-SSE">长连接(SSE)</h3><p>客户端和服务端建立连接后不进行断开，之后客户端再次访问这个服务端上的内容时，继续使用这一条连接通道<br><strong>优点</strong>: 消息即时到达，不发无用请求<br><strong>缺点</strong>: 与长轮询一样，服务器一直保持连接是会消耗资源的，如果有大量的长连接的话，对于服务器的消耗是巨大的，而且服务器承受能力是有上限的，不可能维持无限个长连接。</p><img src="/2023/06/22/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/image-3.png" class="" title="SSE"><h3 id="WebSocket">WebSocket</h3><p>客户端向服务器发送一个携带特殊信息的请求头（Upgrade:WebSocket ）建立连接，建立连接后双方即可实现自由的实时双向通信。<br><strong>优点</strong>:</p><ul class="lvl-0"><li class="lvl-2"><p>较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。</p></li><li class="lvl-2"><p>更强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；即使是和Comet等类似的长轮询比较，其也能在短时间内更多次地传递数据。</p></li><li class="lvl-2"><p>保持连接状态。与HTTP不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。</p></li></ul><p><strong>缺点</strong>: 相对来说，开发成本和难度更高。例如，当连接终止时，WebSockets 无法自动恢复连接。</p><img src="/2023/06/22/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/image-4.png" class="" title="WebSocket"><h2 id="长轮询">长轮询</h2><p>长轮询挂起请求，等待新数据更新后再响应的处理方式虽然能减少浏览器的请求次数，并带来即时性，但是如果使用同步处理请求的方式，挂起请求则代表了线程的阻塞，有多少长轮询请求未响应就代表要阻塞多少个Servlet线程。所以长轮询必须使用异步处理方式。</p><p>流程:</p><ul class="lvl-0"><li class="lvl-2"><p>请求发送到服务器。</p></li><li class="lvl-2"><p>服务器在有新数据之前不会响应请求。</p></li><li class="lvl-2"><p>当新数据出现、或超过预设等待时间时，服务器将对其请求作出响应。</p></li><li class="lvl-2"><p>浏览器立即发出一个新的请求。</p></li></ul><img src="/2023/06/22/%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF/image-5.png" class="" title="异步处理请求"><p>如上图，在主线程中开启异步处理，主线程将请求交给其他线程去处理，主线程就结束了，被放回了主线程池，由其他线程继续处理请求，可以避免主线程池线程耗尽，起到容器线池程和工作线程池隔离的效果。</p><h2 id="案例描述">案例描述</h2><p>用户在网页使用微信扫码登陆，使用手机app扫码后微信服务器向后端服务器回调扫码事件，由于前端无法感知到用户手机扫码的行为，所以停留在扫码登陆页面时需要持续轮询后端服务器用户是否已扫码登录，造成服务器的较大压力，于是利用Servlet3.0的异步特性，实现长轮询的方式来通信。</p><p>前端的扫码登录页面向后端请求微信登录二维码，后端返回微信登录二维码给前端时附带随机生成的scene_id，前端显示二维码供用户手机微信扫码，前端持续轮询后端用户是否已扫码（上一次轮询未成功登陆为开启下一次轮询的条件），但需带上scene_id以区分扫码用户，此时后端不同步返回前端请求结果，而是以异步响应式的方式等待微信服务器回调后，或是超过指定时间例如30秒后再返回（可能用户打开登陆页面后停留但未成功扫码），大大减少了前端访问后端的次数。</p><p>编辑时间</p>]]></content>
    
    
    <categories>
      
      <category>Web设计</category>
      
      <category>Web</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>hexo+github</title>
    <link href="/2023/06/22/hexo-github/"/>
    <url>/2023/06/22/hexo-github/</url>
    
    <content type="html"><![CDATA[<h2 id="Hexo简介">Hexo简介</h2><p>​Hexo是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p><h2 id="Hexo-结构">Hexo 结构</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs xml">.<br>├── _config.yml                     <br>├── package.json<br>├── public                   // 公共文件夹，这个文件夹用于存放生成的站点文件。<br>├── scaffolds                // 模板文件夹，存储page、draft、page的模板<br>├── source                   // 资源文件夹，这个文件夹用来存放内容。<br>|   ├── _drafts                     <br>|   └── _posts<br>└── themes<br></code></pre></td></tr></table></figure><h2 id="Hexo-写作">Hexo 写作</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hexo new [layout] &lt;title&gt;  # 创建一篇新文章或者新页面<br></code></pre></td></tr></table></figure><p>layout: 文章的布局，通过_config.yml中的default_layout参数指定默认布局</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">git init<br>git add .<br>git commit -m &quot;first commit&quot;<br>git branch -M main<br>git remote <br>git <br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
